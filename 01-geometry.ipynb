{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import pooch\n",
    "import requests\n",
    "import pyproj\n",
    "import geojson\n",
    "import rasterio\n",
    "import pysheds, pysheds.grid, pysheds.view\n",
    "import firedrake\n",
    "import icepack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll download a 1/3-arcsecond DEM of the region we're interested in.\n",
    "The DEM comes from the Oregon Lidar Consortium, which is part of the Oregon Department of Geology and Mineral Industries (DOGAMI).\n",
    "The DOGAMI website has an interactive online [viewer](https://gis.dogami.oregon.gov/maps/lidarviewer/) and download utility for LiDAR data.\n",
    "The code below uses a library called [pooch](https://www.fatiando.org/pooch) to describe what file we want to get and from where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.oregongeology.org/pubs/ldq/\"\n",
    "archive_filename = \"LDQ-43124D1.zip\"\n",
    "checksum = \"cb1fcb26fbb6e84640a554fb2287c619cfe6f54bc81a6423624273ceb21f7647\"\n",
    "dem = pooch.create(\n",
    "    path=pooch.os_cache(\"hillslope\"),\n",
    "    base_url=url,\n",
    "    registry={archive_filename: checksum},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll actually fetch the raw data, unzip it, and extract a `.adf` file (an ArcInfo binary format) containing the actual DEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    downloader = pooch.HTTPDownloader(progressbar=True)\n",
    "    files = dem.fetch(\n",
    "        archive_filename,\n",
    "        processor=pooch.Unzip(),\n",
    "        downloader=downloader,\n",
    "    )\n",
    "except requests.exceptions.SSLError:\n",
    "    downloader = pooch.HTTPDownloader(progressbar=True, verify=False)\n",
    "    files = dem.fetch(\n",
    "        archive_filename,\n",
    "        processor=pooch.Unzip(),\n",
    "        downloader=downloader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = [\n",
    "    f for f in files if \"South Coast\" in f and \"Bare_Earth\" in f and \"w001001.adf\" in f\n",
    "][0]\n",
    "\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The region we're interested in is near 43.464N, 124.119W (see the caption to figure 5 of Roering 2008).\n",
    "We'll look at everything within a few hundred feet to make sure we get the whole study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oregon_gic_lambert = pyproj.CRS(3644)\n",
    "lat_lon = pyproj.CRS(4326)\n",
    "transformer = pyproj.Transformer.from_crs(lat_lon, oregon_gic_lambert)\n",
    "\n",
    "lon, lat = -124.119, 43.464\n",
    "x, y = transformer.transform(lat, lon)\n",
    "\n",
    "Lx, Ly = 2000.0, 2000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll extract only a small window around the study area so that we don't waste a ton of computing time later calculating upslope areas that we won't use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = rasterio.open(filename, \"r\")\n",
    "transform = source.transform\n",
    "window = (\n",
    "    rasterio.windows.from_bounds(x - Lx, y - Ly, x + Lx, y + Ly, transform)\n",
    "    .round_lengths()\n",
    "    .round_offsets()\n",
    ")\n",
    "dem = source.read(indexes=1, window=window, masked=True)\n",
    "left, bottom, right, top = rasterio.windows.bounds(window, transform)\n",
    "transform = rasterio.windows.transform(window, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect(\"equal\")\n",
    "extent = (left, right, bottom, top)\n",
    "colors = ax.imshow(dem, vmin=0.0, vmax=1200.0, extent=extent)\n",
    "ax.scatter([x], [y], color=\"tab:red\")\n",
    "fig.colorbar(colors);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use the pysheds package to compute the catchment areas.\n",
    "The steps here are to (1) add the elevation data, (2) fill depressions that won't drain out of the domain, (3) remove flat parts of the DEM where a flow direction can't meaningfully be defined, (4) calculate flow directions using the D${}^\\infty$ routing algorithm from [Tarboton 1997](https://doi.org/10.1029/96WR03137), and (5) calculate the accumulation or catchment area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewfinder = pysheds.view.ViewFinder(affine=transform, shape=dem.shape, crs=oregon_gic_lambert)\n",
    "raster = pysheds.view.Raster(dem, viewfinder)\n",
    "grid = pysheds.grid.Grid(viewfinder=viewfinder).from_raster(raster)\n",
    "flooded_elevation = grid.fill_depressions(raster)\n",
    "inflated_elevation = grid.resolve_flats(flooded_elevation)\n",
    "flow_dir = grid.flowdir(inflated_elevation, routing=\"dinf\")\n",
    "accumulation = grid.accumulation(flow_dir, routing=\"dinf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accumulation area is best viewed on a logarithmic scale.\n",
    "The bright yellow areas are ridge tops, and the dark blue areas are valleys and often rivers.\n",
    "Moreover, the Roering 2008 paper specifies that we want to focus only on the parts of the domain where the accumulation area is less than 250 m${}^2$ = 3.284${}^2$ $\\times$ 250 ft${}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meters_to_feet = 3.284\n",
    "vmax = meters_to_feet**2 * 250\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "norm = LogNorm(vmin=1, vmax=vmax + 1)\n",
    "image = axes.imshow(accumulation + 1, extent=extent, cmap=\"viridis_r\", norm=norm)\n",
    "fig.colorbar(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next plot shows the elevation with the valleys masked out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = accumulation > vmax\n",
    "elevation_masked = ma.masked_array(raster, mask=mask)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "axes.ticklabel_format(axis=\"both\", style=\"scientific\", scilimits=(0, 0))\n",
    "image = axes.imshow(elevation_masked, extent=extent)\n",
    "fig.colorbar(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to digitize the outline of the domain that we want to simulate into some vector format.\n",
    "First, we'll save the DEM and catchment area to GeoTIFF files so that we can open them in a GIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = {\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"count\": 1,\n",
    "    \"height\": dem.shape[0],\n",
    "    \"width\": dem.shape[1],\n",
    "    \"crs\": \"EPSG:3644\",\n",
    "    \"transform\": transform,\n",
    "    \"dtype\": np.float64,\n",
    "}\n",
    "\n",
    "with rasterio.open(\"elevation.tif\", \"w\", **profile) as destination:\n",
    "    destination.write(dem, indexes=1)\n",
    "\n",
    "with rasterio.open(\"catchment.tif\", \"w\", **profile) as destination:\n",
    "    destination.write(accumulation, indexes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outside of this notebook, I opened the DEM and catchment area files in a GIS, manually traced out the boundaries of the hillslope we're interested in, and saved them to GeoJSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = pathlib.Path(\"./\").glob(\"sullivan-creek[0-9].geojson\")\n",
    "outlines = []\n",
    "for filename in input_files:\n",
    "    with open(filename, \"r\") as outline_file:\n",
    "        outline = geojson.load(outline_file)\n",
    "        outlines.append(outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to mesh the outline.\n",
    "The code below creates one feature collection from all of the outlines and does a bit of cleanup on them so that it's easy to detect where one segment of the boundary matches up with another segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sum((outline[\"features\"] for outline in outlines), [])\n",
    "crs = {\"type\": \"name\", \"properties\": {\"name\": \"urn:ogc:def:crs:EPSG::3644\"}}\n",
    "collection = geojson.FeatureCollection(features, crs=crs, name=\"sullivan-creek\")\n",
    "outline = icepack.meshing.normalize(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meshing module in icepack includes a routine to turn a normalized GeoJSON outline into the input format for the mesh generator gmsh.\n",
    "The file extension for gmsh geometry files is `.geo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = icepack.meshing.collection_to_geo(outline)\n",
    "with open(\"sullivan-creek.geo\", \"w\") as geometry_file:\n",
    "    geometry_file.write(geometry.get_code())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can make a command-line call to gmsh to triangulate the interior of the outline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gmsh -2 -v 0 -format msh2 -o sullivan-creek.msh sullivan-creek.geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read that outline into a Firedrake mesh object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = firedrake.Mesh(\"sullivan-creek.msh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots()\n",
    "norm = LogNorm(vmin=1, vmax=vmax + 1)\n",
    "image = axes.imshow(accumulation + 1, extent=extent, cmap=\"viridis_r\", norm=norm)\n",
    "fig.colorbar(image)\n",
    "\n",
    "coords = mesh.coordinates.dat.data_ro\n",
    "δ = 250.0\n",
    "axes.set_xlim((coords[:, 0].min() - δ, coords[:, 0].max() + δ))\n",
    "axes.set_ylim((coords[:, 1].min() - δ, coords[:, 1].max() + δ))\n",
    "firedrake.triplot(mesh, interior_kw={\"linewidth\": 0.1}, axes=axes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a workable geometry for the spatial domain, we can start on the modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firedrake",
   "language": "python",
   "name": "firedrake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
